# ğŸ‘• Fashion MNIST Image Classification â€” Turing Test '25 (Wildcard Round)

**Author:** Anushka Chandel  
**Branch:** CSE-1  
**Roll No.:** 2400270100042  

This repository contains my submission for **The Turing Testâ€™25 â€” Wildcard Round (ML Track)**.

---

## ğŸ”§ Tech Stack
- Python 3.10+
- TensorFlow / Keras
- NumPy, Matplotlib, scikit-learn

---

## ğŸ“‚ Repository Structure
```
.
â”œâ”€â”€ fashion_mnist.ipynb        # Colab-ready notebook
â”œâ”€â”€ train.py                   # Training script
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ README.md                  # Project overview
â”œâ”€â”€ REPORT.md                  # Detailed write-up
â”œâ”€â”€ fashion_model.keras        # Saved trained model
â”œâ”€â”€ classification_report.txt  # Model evaluation report
â””â”€â”€ confusion_matrix.png       # Visualization
```

---

## â–¶ï¸ Quickstart (Colab â€” Recommended)
1. Open **Google Colab**.
2. Upload `fashion_mnist.ipynb` to Colab.
3. Click **Runtime â†’ Run all** (or run cells step-by-step).
4. The notebook will:
   - Load Fashion MNIST from Keras (no manual download needed)
   - Build & train a CNN with data augmentation
   - Evaluate on the test set (accuracy + confusion matrix + report)
   - Save the trained model as `fashion_model.keras`
5. Download the saved model (`fashion_model.keras`) from the Colab file browser.

---

## â–¶ï¸ Quickstart (Local)
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
python train.py --epochs 12 --batch_size 128 --out fashion_model.keras
```
This will create:
- `fashion_model.keras` â€” the trained model
- `training_history.json` â€” accuracy & loss history
- `confusion_matrix.png` â€” normalized confusion matrix

---

## ğŸ§  Model (High-level)
- Input: 28Ã—28 grayscale images (normalized to [0, 1])
- Architecture: Conv â†’ Conv â†’ MaxPool â†’ Dropout â†’ Conv â†’ Conv â†’ MaxPool â†’ Dropout â†’ Dense
- Regularization: Data Augmentation + Dropout
- Optimizer: Adam
- Loss: Sparse Categorical Crossentropy
- EarlyStopping & ModelCheckpoint callbacks

---

## ğŸ“Š Results
- **Validation Accuracy:** 0.9158
- **Test Accuracy:** 0.9077
- **Test Loss:** 0.2607

ğŸ“Œ Confusion Matrix:  
![Confusion Matrix](confusion_matrix.png)

---

## ğŸ” Reproducibility
Set random seeds inside the notebook/script for consistent runs. Use the same `epochs`, `batch_size`, and architecture to match results.

---

## âœ¨ Originality
- Used **data augmentation** for better generalization  
- Applied **EarlyStopping + ModelCheckpoint**  
- Included **confusion matrix and classification report** for clarity  

---

## ğŸ“Œ Future Improvements
- Explore deeper CNNs or transfer learning (e.g., MobileNetV2)  
- Hyperparameter tuning (learning rate, batch size, etc.)  
- Use cross-validation for robustness  

---

## âœ… Submission Notes
- Repo contains source code, trained model, and documentation  
- All results are reproducible via notebook or script  
- Submission prepared for **ML-COE Wildcard Round 2025**  

---
